{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# CutMix Augmentation for Image Classification\n",
    "\n",
    "**Author:** [Sayan Nath](https://twitter.com/SayanNa20204009)<br>\n",
    "**Date created:** 2021/03/25<br>\n",
    "**Last modified:** 2021/03/25<br>\n",
    "**Description:** Data augmentation using the CutMix technique for image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "_CutMix_ is a data augmentation technique proposed in [CutMix: Regularization Strategy to\n",
    "Train Strong Classifiers with Localizable Features](https://arxiv.org/pdf/1905.04899.pdf)\n",
    "by Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun,\n",
    "Junsuk Choe, Youngjoon Yoo.\n",
    "\n",
    "In CutMix Augmentation technique,instead of removing pixels and filling them with black\n",
    "or grey pixels or Gaussian noise a patch of similar dimension is placed from another\n",
    "image.\n",
    "\n",
    "The ground truth labels are mixed proportionally to the number of pixels of combined\n",
    "images. The labels which are linearly iinterpolated label which gets produced is\n",
    "proportional to the pixels which are contributing from the two images.\n",
    "\n",
    "CutMix Augmentation is used when there is presence of uninformative pixel during training.\n",
    "\n",
    "It's implemented with the following formulas:\n",
    "\n",
    "<img height=100 width=250\n",
    "src=\"https://raw.githubusercontent.com/sayannath/CutMix-Augmentation---Keras/main/assets/cutmix-1.png?token=AKAF55CUC3LRB4YI7RXCO3TAMXKHU\">\n",
    "\n",
    "\n",
    "\n",
    "where M is the binary mask which indicates the cutout and the fill-in regions from the\n",
    "two randomly drawn images and \u00ce\u00bb is drawn from [Beta(\u00ce\u00b1,\u00ce\u00b1)\n",
    "distribution](https://en.wikipedia.org/wiki/Beta_distribution) and `\u00ce\u00bb \u00e2\u02c6\u02c6 [0, 1]`\n",
    "\n",
    "\n",
    "The coordinates of bounding boxes are <img height=40 width=150\n",
    "src=\"https://raw.githubusercontent.com/sayannath/CutMix-Augmentation---Keras/main/assets/c\n",
    "utmix-3.png?token=AKAF55G3SW73WB34GD74ARDAMXKCA\"> which indicates the cutout and fill-in\n",
    "regions in case of the images.\n",
    "\n",
    "The bounding box sampling is represented by:\n",
    "\n",
    "<img height=100 width=250\n",
    "src=\"https://raw.githubusercontent.com/sayannath/CutMix-Augmentation---Keras/main/assets/cutmix-2.png?token=AKAF55CDRYZPUHPXDVCGUODAMXKRS\">\n",
    "\n",
    "where `rx,ry` are randomly drawn from a uniform distribution with upper bound\n",
    "\n",
    "This example requires TensorFlow 2.4 or higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import resnet50\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Load the CIFAR10 dataset\n",
    "\n",
    "For this example, we will be using the\n",
    "[CIFAR10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "y_train = pd.get_dummies(y_train.flatten()).values.astype(np.float32)\n",
    "y_test = pd.get_dummies(y_test.flatten()).values.astype(np.float32)\n",
    "\n",
    "class_names = [\n",
    "    \"Airplane\",\n",
    "    \"Automobile\",\n",
    "    \"Bird\",\n",
    "    \"Cat\",\n",
    "    \"Deer\",\n",
    "    \"Dog\",\n",
    "    \"Frog\",\n",
    "    \"Horse\",\n",
    "    \"Ship\",\n",
    "    \"Truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "IMG_SHAPE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SHAPE, IMG_SHAPE))\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Convert the data into TensorFlow `Dataset` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_ds_one = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .shuffle(1024)\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    ")\n",
    "train_ds_two = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .shuffle(1024)\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    ")\n",
    "\n",
    "train_ds_simple = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "train_ds_simple = (\n",
    "    train_ds_simple.map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "# We will be combining two shuffled datasets from the same training data.\n",
    "train_ds = tf.data.Dataset.zip((train_ds_one, train_ds_two))\n",
    "\n",
    "test_ds = (\n",
    "    test_ds.map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##Define the CutMix Technique Function\n",
    "\n",
    "cutmix function takes two `image` and `label` pair and performs cutmix augmentation. It\n",
    "samples `\u00ce\u00bb(l)` from a [Beta\n",
    "Distribution](https://en.wikipedia.org/wiki/Beta_distribution) and we get the bounding\n",
    "box from get_box function. We crop the image2 and pad this image in the final padded\n",
    "image at the same location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def get_box(l):\n",
    "    cut_rat = tf.math.sqrt(1.0 - l)\n",
    "\n",
    "    cut_w = IMG_SHAPE * cut_rat  # rw\n",
    "    cut_w = tf.cast(cut_w, tf.int32)\n",
    "\n",
    "    cut_h = IMG_SHAPE * cut_rat  # rh\n",
    "    cut_h = tf.cast(cut_h, tf.int32)\n",
    "\n",
    "    cx = tf.random.uniform((1,), minval=0, maxval=IMG_SHAPE, dtype=tf.int32)  # rx\n",
    "    cy = tf.random.uniform((1,), minval=0, maxval=IMG_SHAPE, dtype=tf.int32)  # ry\n",
    "\n",
    "    bbx1 = tf.clip_by_value(cx[0] - cut_w // 2, 0, IMG_SHAPE)\n",
    "    bby1 = tf.clip_by_value(cy[0] - cut_h // 2, 0, IMG_SHAPE)\n",
    "    bbx2 = tf.clip_by_value(cx[0] + cut_w // 2, 0, IMG_SHAPE)\n",
    "    bby2 = tf.clip_by_value(cy[0] + cut_h // 2, 0, IMG_SHAPE)\n",
    "\n",
    "    target_h = bby2 - bby1\n",
    "    if target_h == 0:\n",
    "        target_h += 1\n",
    "\n",
    "    target_w = bbx2 - bbx1\n",
    "    if target_w == 0:\n",
    "        target_w += 1\n",
    "\n",
    "    return bbx1, bby1, target_h, target_w\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def cutmix(a, b):\n",
    "\n",
    "    (image1, label1), (image2, label2) = a, b\n",
    "\n",
    "    alpha = [1.0]\n",
    "    beta = [1.0]\n",
    "\n",
    "    ## Get sample from beta distribution\n",
    "    dist = tfd.Beta(alpha, beta)\n",
    "    ## Lambda\n",
    "    l = dist.sample(1)[0][0]\n",
    "\n",
    "    ## Get bbox ofsets and heights and widths\n",
    "    bbx1, bby1, target_h, target_w = get_box(l)\n",
    "\n",
    "    ## Get patch from image2\n",
    "    crop2 = tf.image.crop_to_bounding_box(image2, bby1, bbx1, target_h, target_w)\n",
    "    ## Pad the patch with same offset\n",
    "    image2 = tf.image.pad_to_bounding_box(crop2, bby1, bbx1, IMG_SHAPE, IMG_SHAPE)\n",
    "    ## Get patch from image1\n",
    "    crop1 = tf.image.crop_to_bounding_box(image1, bby1, bbx1, target_h, target_w)\n",
    "    ## Pad the patch with same offset\n",
    "    img1 = tf.image.pad_to_bounding_box(crop1, bby1, bbx1, IMG_SHAPE, IMG_SHAPE)\n",
    "\n",
    "    ## Subtract the patch from image1 so that patch from image2 can be put on instead\n",
    "    image1 = image1 - img1\n",
    "    ## Add modified image1 and image2 to get cutmix image\n",
    "    image = image1 + image2\n",
    "\n",
    "    ## Adjust lambda according to pixel ration\n",
    "    l = 1 - (target_w * target_h) / (IMG_SHAPE * IMG_SHAPE)\n",
    "    l = tf.cast(l, tf.float32)\n",
    "\n",
    "    ## Combine labels\n",
    "    label = l * label1 + (1 - l) * label2\n",
    "\n",
    "    return image, label\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Note** that here , we are combining two images to create a single one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Visualize the new dataset after applying CutMix Augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Create the new dataset using our `mix_up` utility\n",
    "train_ds_cmu = (\n",
    "    train_ds.shuffle(1024)\n",
    "    .map(cutmix, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "# Let's preview 9 samples from the dataset\n",
    "image_batch, label_batch = next(iter(train_ds_cmu))\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.title(class_names[np.argmax(label_batch[i])])\n",
    "    plt.imshow(image_batch[i])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def resnet_layer(\n",
    "    inputs,\n",
    "    num_filters=16,\n",
    "    kernel_size=3,\n",
    "    strides=1,\n",
    "    activation=\"relu\",\n",
    "    batch_normalization=True,\n",
    "    conv_first=True,\n",
    "):\n",
    "\n",
    "    conv = keras.layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=keras.regularizers.l2(1e-4),\n",
    "    )\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = keras.layers.Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = keras.layers.Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v20(input_shape, depth, num_classes=10):\n",
    "\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError(\"depth should be 6n+2 (eg 20, 32, 44 in [a])\")\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = keras.layers.Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x, num_filters=num_filters, strides=strides)\n",
    "            y = resnet_layer(inputs=y, num_filters=num_filters, activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(\n",
    "                    inputs=x,\n",
    "                    num_filters=num_filters,\n",
    "                    kernel_size=1,\n",
    "                    strides=strides,\n",
    "                    activation=None,\n",
    "                    batch_normalization=False,\n",
    "                )\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = keras.layers.Activation(\"relu\")(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = keras.layers.AveragePooling2D(pool_size=8)(x)\n",
    "    y = keras.layers.Flatten()(x)\n",
    "    outputs = keras.layers.Dense(\n",
    "        num_classes, activation=\"softmax\", kernel_initializer=\"he_normal\"\n",
    "    )(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def training_model():\n",
    "    return resnet_v20((32, 32, 3), 20)\n",
    "\n",
    "\n",
    "initial_model = training_model()\n",
    "initial_model.save_weights(\"initial_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 1. Train the model with the CutMix Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = training_model()\n",
    "model.load_weights(\"initial_weights.h5\")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_ds_cmu, validation_data=test_ds, epochs=10)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(\"Test accuracy: {:.2f}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 2. Train the model with the Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = training_model()\n",
    "model.load_weights(\"initial_weights.h5\")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_ds_simple, validation_data=test_ds, epochs=10)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(\"Test accuracy: {:.2f}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Notes\n",
    "\n",
    "In this example, we trained our model for 15 epochs. On the CIFAR10 dataset, the model\n",
    "performs better with `CutMix Augmentation` with a better accuracy (for example 80.02% in\n",
    "one experiment) compared to model with a accuracy (for example 74.20%).\n",
    "\n",
    "In the notebook, you may notice that, the time taken during the CutMix Augmentation.\n",
    "\n",
    "You can also experiment this `CutMix` technique by reading this [Original\n",
    "Paper](https://arxiv.org/pdf/1905.04899.pdf)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "..\\examples\\vision\\cutmix",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}