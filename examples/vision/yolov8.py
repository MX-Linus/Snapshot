# -*- coding: utf-8 -*-
"""kerascv_yolov8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1edyFfAEbH07sb8XB72GlMLphw6BKnE23
"""

!!pip install --upgrade git+https://github.com/keras-team/keras-cv -q

"""# Imports"""

import os
import resource
import numpy as np
import tqdm

import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow import keras
from tensorflow.keras import optimizers

import keras_cv
from keras_cv import bounding_box
from keras_cv import visualization

"""# Define hyperparameters"""

BATCH_SIZE = 16
LEARNING_RATE = 1e-6
IMG_SIZE = 640
EPOCHS = 5

"""#Class Maping"""

class_ids = [
    "Aeroplane",
    "Bicycle",
    "Bird",
    "Boat",
    "Bottle",
    "Bus",
    "Car",
    "Cat",
    "Chair",
    "Cow",
    "Dining Table",
    "Dog",
    "Horse",
    "Motorbike",
    "Person",
    "Potted Plant",
    "Sheep",
    "Sofa",
    "Train",
    "Tvmonitor",
    "Total",
]
class_mapping = dict(zip(range(len(class_ids)), class_ids))

"""# Pascal Voc 2007 Dataset

 loading the "voc/2007" dataset, which is a popular computer vision dataset that contains images and corresponding object annotations.
The "split" parameter is used to specify which subset of the dataset to load. In this case, "train" is used to load the training set, and "validation" is used to load the validation set.
The "with_info" parameter is set to False, which means that the dataset metadata will not be returned along with the dataset.
The "shuffle_files" parameter is set to True, which means that the order of the files in the dataset will be randomized. This is useful for preventing any biases that may be introduced by the order of the files.
Overall, this code is loading the "voc/2007" dataset into two separate datasets, one for training and one for validation, with the files shuffled to prevent any biases.


"""

train_ds = tfds.load("voc/2007", split="train", with_info=False, shuffle_files=True)
val_ds = tfds.load("voc/2007", split="validation", with_info=False, shuffle_files=True)

def prepare_dataset(inputs):
  image = inputs['image']
  bbox = keras_cv.bounding_box.convert_format(inputs['objects']['bbox'], 
                                             images=image, 
                                             source='rel_yxyx', 
                                             target="xywh")
  bounding_boxes = {
        "classes": tf.cast(inputs["objects"]["label"], dtype=tf.float32),
        "boxes": tf.cast(bbox, dtype=tf.float32),
    }
  return {"images": tf.cast(image, tf.float32), "bounding_boxes": bounding_boxes}

def dict_to_tuple(inputs):
    return inputs["images"], bounding_box.to_dense(
        inputs["bounding_boxes"], max_boxes=32
    )
    
resizing_layer = keras_cv.layers.Resizing(
    640, 640, bounding_box_format="xywh", pad_to_aspect_ratio=True
)

"""# Prepare Train Dataset"""

train_ds = train_ds.map(prepare_dataset, num_parallel_calls=tf.data.AUTOTUNE)
train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)
train_ds = train_ds.map(resizing_layer, num_parallel_calls=tf.data.AUTOTUNE)

"""# Visualize Train Dataset"""

def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):
    inputs = next(iter(inputs.take(1)))
    images, bounding_boxes = inputs["images"], inputs["bounding_boxes"]
    visualization.plot_bounding_box_gallery(
        images,
        value_range=value_range,
        rows=rows,
        cols=cols,
        y_true=bounding_boxes,
        scale=5,
        font_scale=0.7,
        bounding_box_format=bounding_box_format,
        class_mapping=class_mapping,
    )

visualize_dataset(
    train_ds, bounding_box_format="xywh", value_range=(0, 255), rows=2, cols=2
)

train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)
train_ds = train_ds.prefetch(tf.data.AUTOTUNE)

"""# Prepare Validation dataset"""

val_ds = val_ds.map(prepare_dataset, num_parallel_calls=tf.data.AUTOTUNE)
val_ds = val_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)
val_ds = val_ds.map(resizing_layer, num_parallel_calls=tf.data.AUTOTUNE)
val_ds = val_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)
val_ds = val_ds.prefetch(tf.data.AUTOTUNE)

"""# YOLOV8 Model

YOLOv8 is the newest state-of-the-art YOLO model that can be used for object detection, image classification, and instance segmentation tasks. YOLOv8 was developed by Ultralytics. YOLOv8 is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection and tracking, instance segmentation, image classification and pose estimation tasks.
"""

yolo = keras_cv.models.YOLOV8Detector(
            num_classes=2,
            fpn_depth=1,
            bounding_box_format="xywh",
            backbone=keras_cv.models.YOLOV8Backbone.from_preset(
                "yolo_v8_s_backbone_coco"
            ),
        )

"""# Loss Function

The "classification_loss" parameter is set to "binary_crossentropy", which is a common loss function used for binary classification tasks. This loss function measures the difference between the predicted class probabilities and the true class labels.

The "box_loss" parameter is set to "iou", which stands for Intersection over Union. This is a loss function that measures the difference between the predicted bounding boxes and the true bounding boxes. It is commonly used for object detection tasks.
"""

yolo.compile(
    classification_loss="binary_crossentropy",
    box_loss="iou",
    optimizer="adam",
)

yolo.fit(
    train_ds.take(100),
    validation_data=val_ds.take(100),
    epochs=5,
)

def visualize_detections(model, dataset, bounding_box_format):
    images, y_true = next(iter(dataset.take(1)))
    y_pred = model.predict(images)
    y_pred = bounding_box.to_ragged(y_pred)
    visualization.plot_bounding_box_gallery(
        images,
        value_range=(0, 255),
        bounding_box_format=bounding_box_format,
        y_true=y_true,
        y_pred=y_pred,
        scale=4,
        rows=2,
        cols=2,
        show=True,
        font_scale=0.7,
        class_mapping=class_mapping,
    )

visualize_detections(yolo, dataset=val_ds, bounding_box_format="xywh")