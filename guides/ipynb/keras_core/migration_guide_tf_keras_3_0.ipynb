{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Migration guide : Tensorflow to Keras 3.0\n",
    "\n",
    "**Author:** [Divyashree Sreepathihalli](https://github.com/divyashreepathihalli)<br>\n",
    "**Date created:** 2023/10/23<br>\n",
    "**Last modified:** 2023/10/30<br>\n",
    "**Description:** Instructions on migrating your TensorFlow code to Keras 3.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This guide will help you migrate code from TensorFlow 2.x to keras 3.0. The overhead for\n",
    "the migration is minimal. But once you have migrated you can run Keras workflows on top\n",
    "of arbitrary frameworks \u2014 starting with TensorFlow, JAX, and PyTorch.\n",
    "\n",
    "Keras 3.0 is also a drop-in replacement for `tf.keras`, with near-full backwards\n",
    "compatibility with `tf.keras` code when using the TensorFlow backend. In the vast\n",
    "majority of cases you can just start importing it via `import keras` in place of `from\n",
    "tensorflow import keras` and your existing code will run with no issue \u2014 and generally\n",
    "with slightly improved performance, thanks to XLA compilation.\n",
    "\n",
    "Commonly encountered issues and frequently asked questions can be located in\n",
    "the following links.\n",
    "\n",
    "[Known\n",
    "Issues](https://keras.io/keras_core/announcement/#:~:text=Enjoy%20the%20library!-,Known%20issues,-Keras%20Core%20is)\n",
    "\n",
    "[FAQs](https://keras.io/keras_core/announcement/#:~:text=Frequently%20asked%20questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Setup\n",
    "\n",
    "First, lets install keras-nightly.\n",
    "\n",
    "We're going to be using the Tensorflow backend here -- but you can edit the string below\n",
    "to \"tensorflow\" or \"torch\" and hit \"Restart runtime\", once you have migrated your code\n",
    "and your code will run just the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!! pip install keras-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Switching Tensorflow code to Keras 3.0 - Tensorflow backend\n",
    "\n",
    "Follow these instructions to migrate your existing TensorFlow code to Keras 3.0 and run\n",
    "it with the TensorFlow backend:\n",
    "\n",
    "1.   Update imports : replace `from tensorflow import keras` to `import keras`\n",
    "2.   Update code : replace `tf.keras.*` to `keras.*`\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Migration incompatabilities : `tf.keras` to `keras 3.0`\n",
    "Keras 3 is a significant milestone in the evolution of the Keras API. It features a\n",
    "number of cleanups and modernizations that have resulted in a few breaking changes\n",
    "compared to Keras 2. All APIs that were removed were dropped due to extremely low usage.\n",
    "\n",
    "The following list provides a comprehensive overview of the breaking changes in Keras 3.\n",
    "While the majority of these changes are unlikely to affect most users, a small number of\n",
    "them may require code changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### `jit_compile` is set to `True` by default\n",
    "The default value of the `jit_compile` argument to the Model constructor has been set to\n",
    "`True` in Keras 3. This means that models will be compiled with Just-In-Time (JIT)\n",
    "compilation by default.\n",
    "\n",
    "JIT compilation can improve the performance of some models. However, it may not work with\n",
    "all TensorFlow operations. If you are using a custom model or layer and you see an\n",
    "XLA-related error, you may need to set the jit_compile argument to False. Here is a list\n",
    "of known issues encountered when using xla with tensorflow backend -\n",
    "https://www.tensorflow.org/xla/known_issues. In addition to these issues, there are some\n",
    "ops that are not supported by XLA.\n",
    "\n",
    "The error message you could encounter would be as follows:\n",
    "\n",
    "\n",
    "```Detected unsupported operations when trying to compile graph\n",
    "__inference_one_step_on_data_125[] on XLA_CPU_JIT```\n",
    "\n",
    "The following snippet of code will reproduce the above error:\n",
    "\n",
    "```\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        string_input = tf.strings.as_string(inputs)\n",
    "        return tf.strings.to_number(string_input)\n",
    "\n",
    "\n",
    "subclass_model = MyModel()\n",
    "x_train = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "y_train = np.array([[\"1\", \"2\", \"3\"], [\"4\", \"5\", \"6\"]])\n",
    "subclass_model.compile(optimizer=\"sgd\", loss=\"mse\")\n",
    "subclass_model.fit(x_train, x_train, epochs=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Here is how you fix it:\n",
    "\n",
    "set `jit_compile=False` in `model.compile(..., jit_compile=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        string_input = tf.strings.as_string(inputs)\n",
    "        return tf.strings.to_number(string_input)\n",
    "\n",
    "\n",
    "subclass_model = MyModel()\n",
    "x_train = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "y_train = np.array([[\"1\", \"2\", \"3\"], [\"4\", \"5\", \"6\"]])\n",
    "subclass_model.compile(optimizer=\"sgd\", loss=\"mse\", jit_compile=False)\n",
    "subclass_model.fit(x_train, x_train, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Saving model in TF SavedModel format\n",
    "Saving to TF SavedModel format via `model.save()` is no longer supported.\n",
    "\n",
    "\n",
    "The error message you could encounter would be as follows:\n",
    "\n",
    "```\n",
    "ValueError: Invalid filepath extension for saving. Please add either a `.keras` extension\n",
    "for the native Keras format (recommended) or a `.h5` extension. Use\n",
    "`tf.saved_model.save()` if you want to export a SavedModel for use with\n",
    "TFLite/TFServing/etc. Received: filepath=saved_model.\n",
    "```\n",
    "\n",
    "The following snippet of code will reproduce the above error:\n",
    "\n",
    "```\n",
    "sequential_model = keras.Sequential([\n",
    "    keras.layers.Dense(2)\n",
    "])\n",
    "sequential_model.save(\"saved_model\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Here is how you fix it:\n",
    "\n",
    "use `tf.saved_model.save` instead of `model.save`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "sequential_model = keras.Sequential([keras.layers.Dense(2)])\n",
    "tf.saved_model.save(sequential_model, \"saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Load a TF SavedModel\n",
    "Loading a TF SavedModel file via keras.models.load_model() is no longer supported\n",
    "\n",
    "if you try to use `keras.models.load_model` you would get the following error\n",
    "```\n",
    "ValueError: File format not supported: filepath=saved_model. Keras 3 only supports V3\n",
    "`.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy\n",
    "SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a\n",
    "TensorFlow SavedModel as an inference-only layer in Keras 3, use\n",
    "`keras.layers.TFSMLayer(saved_model, call_endpoint='serving_default')` (note that your\n",
    "`call_endpoint` might have a different name).\n",
    "```\n",
    "\n",
    "The following snippet of code will reproduce the above error:\n",
    "\n",
    "```\n",
    "keras.models.load_model(\"saved_model\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Here is how you fix it:\n",
    "\n",
    "Use `keras.layers.TFSMLayer(filepath, call_endpoint=\"serving_default\")` to reload any TF\n",
    "SavedModel as a Keras layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "keras.layers.TFSMLayer(\"saved_model\", call_endpoint=\"serving_default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Nested inputs to Model()\n",
    "Model() can no longer be passed deeply nested inputs/outputs (nested more than 1 level\n",
    "deep, e.g. lists of lists of tensors)\n",
    "\n",
    "you would encounter errors as follows:\n",
    "\n",
    "```\n",
    "ValueError: When providing `inputs` as a dict, all values in the dict must be\n",
    "KerasTensors. Received: inputs={'foo': <KerasTensor shape=(None, 1), dtype=float32,\n",
    "sparse=None, name=foo>, 'bar': {'baz': <KerasTensor shape=(None, 1), dtype=float32,\n",
    "sparse=None, name=bar>}} including invalid value {'baz': <KerasTensor shape=(None, 1),\n",
    "dtype=float32, sparse=None, name=bar>} of type <class 'dict'>\n",
    "```\n",
    "\n",
    "The following snippet of code will reproduce the above error:\n",
    "\n",
    "```\n",
    "inputs = {\n",
    "    \"foo\": keras.Input(shape=(1,), name=\"foo\"),\n",
    "    \"bar\": {\n",
    "        \"baz\": keras.Input(shape=(1,), name=\"bar\"),\n",
    "    },\n",
    "}\n",
    "outputs = inputs[\"foo\"] + inputs[\"bar\"][\"baz\"]\n",
    "keras.Model(inputs, outputs)\n",
    "```\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Here is how you fix it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"foo\": keras.Input(shape=(1,), name=\"foo\"),\n",
    "    \"baz\": keras.Input(shape=(1,), name=\"bar\"),\n",
    "}\n",
    "outputs = inputs[\"foo\"] + inputs[\"baz\"]\n",
    "keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### TF autograph\n",
    "In old `tf.keras`, TF autograph is enabled by default on the `call()` method of custom\n",
    "layers. In Keras 3, it is not. This means you may have to use cond ops if you're using\n",
    "control flow, or alternatively you can decorate your `call()` method with `@tf.function`.\n",
    "\n",
    "You would encounted an error as follows\n",
    "```\n",
    "OperatorNotAllowedInGraphError: Exception encountered when calling MyCustomLayer.call().\n",
    "\n",
    "Using a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the\n",
    "following resolutions to the problem: If you are running in Graph mode, use Eager\n",
    "execution mode or decorate this function with @tf.function. If you are using AutoGraph,\n",
    "you can try decorating this function with @tf.function. If that does not work, then you\n",
    "may be using an unsupported feature or your source code may not be visible to AutoGraph.\n",
    "See\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/ref\n",
    "erence/limitations.md#access-to-source-code for more information.\n",
    "```\n",
    "\n",
    "The following snippet of code will reproduce the above error:\n",
    "```\n",
    "class MyCustomLayer(keras.layers.Layer):\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "      return inputs * 2\n",
    "    else:\n",
    "      return inputs / 2\n",
    "\n",
    "\n",
    "layer = MyCustomLayer()\n",
    "data = np.random.uniform(size=[3, 3])\n",
    "model = keras.models.Sequential([layer])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.fit(data, data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Here is how you fix it:\n",
    "\n",
    "decorate your `call()` method with `@tf.function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MyCustomLayer(keras.layers.Layer):\n",
    "    @tf.function()\n",
    "    def call(self, inputs):\n",
    "        if tf.random.uniform(()) > 0.5:\n",
    "            return inputs * 2\n",
    "        else:\n",
    "            return inputs / 2\n",
    "\n",
    "\n",
    "layer = MyCustomLayer()\n",
    "data = np.random.uniform(size=[3, 3])\n",
    "model = keras.models.Sequential([layer])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.fit(data, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### TF op on a Keras tensor\n",
    "Using a TF op on a Keras tensor during functional model construction is disallowed: \"A\n",
    "KerasTensor cannot be used as input to a TensorFlow function\".\n",
    "\n",
    "The error you would encounter would be as follows:\n",
    "\n",
    "```\n",
    "ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor\n",
    "is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional\n",
    "models or Keras Functions. You can only use it as input to a Keras layer or a Keras\n",
    "operation (from the namespaces `keras.layers` and `keras.operations`).\n",
    "```\n",
    "\n",
    "The following snippet of code will reproduce the error:\n",
    "\n",
    "```\n",
    "input = keras.layers.Input([2, 2, 1])\n",
    "tf.squeeze(input)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Here is how you fix it:\n",
    "\n",
    "use an equivalent op from `keras.ops`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "input = keras.layers.Input([2, 2, 1])\n",
    "keras.ops.squeeze(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Multi output model\n",
    "Multioutput model's `evaluate()` method does not return individual output losses anymore\n",
    "-> use the metrics argument in compile to track them\n",
    "\n",
    "When having multiple named outputs (for example named output_a and output_b, old tf.keras\n",
    "adds <output_a>_loss, <output_b>_loss and so on to metrics. keras_ 3.0 doesn't add them\n",
    "to metrics and needs to be done them to the output metrics by explicitly providing them\n",
    "in metrics list of individual outputs.\n",
    "\n",
    "The following snippet of code will reproduce the above behavior:\n",
    "\n",
    "```\n",
    "from keras.layers import Input, Dense, Flatten, Softmax\n",
    "# A functional model with multiple outputs\n",
    "inputs = Input(shape=(10,))\n",
    "x1 = Dense(5, activation='relu')(inputs)\n",
    "x2 = Dense(5, activation='relu')(x1)\n",
    "output_1 = Dense(5, activation='softmax', name=\"output_1\")(x1)\n",
    "output_2 = Dense(5, activation='softmax', name=\"output_2\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=[output_1, output_2])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "# dummy data\n",
    "x_test = np.random.uniform(size=[10, 10])\n",
    "y_test = np.random.uniform(size=[10, 5])\n",
    "\n",
    "model.evaluate(x_test, y_test)\n",
    "```\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Softmax\n",
    "\n",
    "# A functional model with multiple outputs\n",
    "inputs = Input(shape=(10,))\n",
    "x1 = Dense(5, activation=\"relu\")(inputs)\n",
    "x2 = Dense(5, activation=\"relu\")(x1)\n",
    "output_1 = Dense(5, activation=\"softmax\", name=\"output_1\")(x1)\n",
    "output_2 = Dense(5, activation=\"softmax\", name=\"output_2\")(x2)\n",
    "# dummy data\n",
    "x_test = np.random.uniform(size=[10, 10])\n",
    "y_test = np.random.uniform(size=[10, 5])\n",
    "multi_output_model = keras.Model(inputs=inputs, outputs=[output_1, output_2])\n",
    "multi_output_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"categorical_crossentropy\", \"categorical_crossentropy\"],\n",
    ")\n",
    "multi_output_model.evaluate(x_test, y_test)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Variables tracking\n",
    "\n",
    "The following snippet of code will show that the tf.Variables are not being tracked.\n",
    "\n",
    "```\n",
    "class MyCustomLayer(keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]\n",
    "        self.w = tf.Variable(initial_value=tf.zeros([input_dim, self.units]))\n",
    "        self.b = tf.Variable(initial_value=tf.zeros([self.units,]))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return keras.ops.matmul(inputs, self.w) + self.b\n",
    "\n",
    "\n",
    "layer = MyCustomLayer(3)\n",
    "data = np.random.uniform(size=[3, 3])\n",
    "model = keras.models.Sequential([layer])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.fit(data, data)\n",
    "# The model does not have any trainable variables\n",
    "for layer in model.layers:\n",
    "    print(layer.trainable_variables)\n",
    "```\n",
    "\n",
    "`UserWarning: The model does not have any trainable weights.\n",
    "  warnings.warn(\"The model does not have any trainable weights.\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Here is how you fix it:\n",
    "\n",
    "use `self.add_weight()` method or use a `keras.Variable` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MyCustomLayer(keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]\n",
    "        self.w = self.add_weight(\n",
    "            shape=[input_dim, self.units],\n",
    "            initializer=\"zeros\",\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=[\n",
    "                self.units,\n",
    "            ],\n",
    "            initializer=\"zeros\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return keras.ops.matmul(inputs, self.w) + self.b\n",
    "\n",
    "\n",
    "layer = MyCustomLayer(3)\n",
    "data = np.random.uniform(size=[3, 3])\n",
    "model = keras.models.Sequential([layer])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.fit(data, data)\n",
    "# Verify that the variables are now being tracked\n",
    "for layer in model.layers:\n",
    "    print(layer.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### None entries are not allowed as part of nested (e.g. list/tuples) tensor arguments in\n",
    "Layer.call(), nor as part of call() return values.\n",
    "\n",
    "The following snippet of code will reproduce the error.\n",
    "\n",
    "```\n",
    "class CustomLayer(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "      return  inputs[\"foo\"]\n",
    "\n",
    "layer = CustomLayer()\n",
    "inputs = {\n",
    "    \"foo\": keras.Input(shape=(1,), name=\"foo\"),\n",
    "    \"bar\": {\n",
    "        \"baz\": None,\n",
    "    },\n",
    "}\n",
    "layer(inputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Here is how you will fix it:\n",
    "\n",
    "Replace `None` with a value or Keras Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class CustomLayer(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = inputs[\"foo\"]\n",
    "        return None\n",
    "\n",
    "\n",
    "layer = CustomLayer()\n",
    "inputs = {\n",
    "    \"foo\": keras.Input(shape=(1,), name=\"foo\"),\n",
    "    \"bar\": {\n",
    "        \"baz\": keras.Input(shape=(1,), name=\"bar\"),\n",
    "    },\n",
    "}\n",
    "layer(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Removed features\n",
    "\n",
    "\n",
    "1. Symbolic `add_loss()`: Symbolic `add_loss()` is removed (you can still use\n",
    "`add_loss()` inside the `call()` method of a layer/model).\n",
    "2. Locally-connected layers: Locally-connected layers are removed due to low usage. To\n",
    "use locally-connected layers, copy the layer implementation into your own codebase.\n",
    "3. Kernelized layers: Kernelized layers are removed due to low usage. To use kernelized\n",
    "layers, copy the layer implementation into your own codebase.\n",
    "4. Removed layer attributes: Layer attributes `metrics`, `dynamic` are removed\n",
    "5. RNN layer args: The `constants` and `time_major` arguments in RNN layers are removed.\n",
    "The `constants` argument was a remnant of Theano and had very low usage. The `time_major`\n",
    "argument was also infrequently used.\n",
    "6. reset_metrics argument: The reset_metrics argument is removed from `model. *_on_batch`\n",
    "methods. This argument had very low usage.\n",
    "7. RadialConstraint: The RadialConstraint constraint object is removed. This object had\n",
    "very low usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Switching Tensorflow code to backend agnostic keras 3.0\n",
    "\n",
    "Keras 3.0 code with the TensorFlow backend will work with native TensorFlow APIs.\n",
    "However, if you want your code to be backend-agnostic, you will need to replace all of\n",
    "the `tf.*` API calls with their equivalent Keras APIs.\n",
    "\n",
    "Follow these instructions to migrate your existing TensorFlow code to Keras 3.0 and run\n",
    "it with any backend of your choice :\n",
    "\n",
    "1. Update imports : replace from tensorflow import keras to import keras\n",
    "2. Update code : replace `tf.keras.*` to `keras.*`. 99% of the tf.keras.* API is\n",
    "consistent with Keras 3.0. Any differences have been called out in this guide. If an API\n",
    "is not specifically called out in this guide, that means that the API call is consistent\n",
    "with tf.keras. If you notice that the same API name results in an error and if it has not\n",
    "been called out in this document the implementation in keras 3.0 was likely dropped due\n",
    "to extremely low usage.\n",
    "3. Replace any `tf.*`, `tf.math*`, `tf.linalg.*`, etc with `keras.ops.*`. Most of the ops\n",
    "should be consistent with Keras 3.0. If the names are slightly different, they will be\n",
    "highlighted in this guide. If the same name results in an error and you do not find a\n",
    "Keras 3.0 equivalent op in this guide, it is likely that the implementation of the op in\n",
    "keras 3.0 was likely dropped due to extremely low usage.\n",
    "4. If you are able to replace all the tf ops with keras, you can remove the tensorflow\n",
    "import and run your code with a backend of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Renamed API calls\n",
    "\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\textbf{`tf.keras`} & \\textbf{`keras 3.0`} \\\\\n",
    "\\hline\n",
    "\\text{tf.keras.layers.ThresholdedReLU} & \\text{keras.layers.ReLU} \\\\ \\hline\n",
    "\\text{tf.keras.constraints.RadialConstraint} & \\text{No equivalent} \\\\ \\hline\n",
    "\\text{tf.keras.mixed_precision.Policy} & \\text{keras.mixed_precision.DTypePolicy} \\\\\n",
    "\\hline\n",
    "\\text{tf.keras.mixed_precision.set_global_policy} &\n",
    "\\text{keras.mixed_precision.set_dtype_policy} \\\\ \\hline\n",
    "\\text{tf.keras.mixed_precision.LossScaleOptimizer} &\n",
    "\\text{keras.mixed_precision.LossScaleOptimizer}\\\\\n",
    "\\text{keras.optimizers.LossScaleOptimizer}  \\\\ \\hline\n",
    "\\text{tf.keras.utils.to_ordinal} & \\text{No equivalent} \\\\ \\hline\n",
    "\\text{tf.keras.backend.rnn} & \\text{keras.layers.rnn} \\\\ \\hline\n",
    "\\text{tf.linalg.normalize} \\\\\n",
    "\\text{tf.math.l2_normalize} & \\text{keras.utils.normalize} \\\\ \\hline\n",
    "\\hline\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Renamed ops\n",
    "\n",
    "Replace any `tf.*`, `tf.math*`, `tf.linalg.*`, etc with `keras.ops.*`. Most of the ops\n",
    "should be consistent with Keras 3.0. If the names are slightly different, they will be\n",
    "highlighted in this guide. If the same name results in an error and you do not find a\n",
    "Keras 3.0 equivalent op in this guide, it is likely that the implementation of the op in\n",
    "keras 3.0 was likely dropped due to extremely low usage.\n",
    "\n",
    "### Numpy ops\n",
    "\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\textbf{TensorFlow} & \\textbf{Keras 3.0} \\\\\n",
    "\\hline\n",
    "\\text{tf.abs} & \\text{keras.ops.absolute} \\\\ \\hline\n",
    "\\text{tf.reduce\\_all} & \\text{keras.ops.all} \\\\ \\hline\n",
    "\\text{tf.reduce\\_max} & \\text{keras.ops.amax} \\\\ \\hline\n",
    "\\text{tf.reduce\\_min} & \\text{keras.ops.amin} \\\\ \\hline\n",
    "\\text{tf.reduce\\_any} & \\text{keras.ops.any} \\\\ \\hline\n",
    "\\text{tf.concat} & \\text{keras.ops.append, keras.ops.concatenate,} \\\\\n",
    " & \\text{keras.ops.hstack, keras.ops.vstack} \\\\ \\hline\n",
    "\\text{tf.range} & \\text{keras.ops.arange} \\\\ \\hline\n",
    "\\text{tf.acos} & \\text{keras.ops.arccos} \\\\ \\hline\n",
    "\\text{tf.asin} & \\text{keras.ops.arcsin} \\\\ \\hline\n",
    "\\text{tf.asinh} & \\text{keras.ops.arcsinh} \\\\ \\hline\n",
    "\\text{tf.atan} & \\text{keras.ops.arctan} \\\\ \\hline\n",
    "\\text{tf.atan2} & \\text{keras.ops.arctan2} \\\\ \\hline\n",
    "\\text{tf.atanh} & \\text{keras.ops.arctanh} \\\\ \\hline\n",
    "\\text{tf.convert_to_tensor} & \\text{keras.ops.array} \\\\ \\hline\n",
    "\\text{tf.reduce_mean} & \\text{keras.ops.average} \\\\ \\hline\n",
    "\\text{tf.clip_by_value} & \\text{keras.ops.clip} \\\\ \\hline\n",
    "\\text{tf.math.conj} & \\text{keras.ops.conjugate, keras.ops.conj} \\\\ \\hline\n",
    "\\text{tf.identity} & \\text{keras.ops.copy} \\\\ \\hline\n",
    "\\text{tf.linalg.diag_part} & \\text{keras.ops.diagonal} \\\\ \\hline\n",
    "\\text{tf.tensordot} & \\text{keras.ops.dot} \\\\ \\hline\n",
    "\\text{tf.constant} & \\text{keras.ops.empty} \\\\ \\hline\n",
    "\\text{tf.reverse} & \\text{keras.ops.flip} \\\\ \\hline\n",
    "\\text{tf.fill} & \\text{keras.ops.full} \\\\ \\hline\n",
    "\\text{tf.ones_like} & \\text{keras.ops.full_like} \\\\ \\hline\n",
    "\\text{tf.gather} & \\text{keras.ops.take} \\\\ \\hline\n",
    "\\text{tf.eye} & \\text{keras.ops.identity} \\\\ \\hline\n",
    "\\text{tf.math.is_close} & \\text{keras.ops.isclose} \\\\ \\hline\n",
    "\\text{tf.math.is_finite} & \\text{keras.ops.isfinite} \\\\ \\hline\n",
    "\\text{tf.math.is_inf} & \\text{keras.ops.isinf} \\\\ \\hline\n",
    "\\text{tf.math.is_nan} & \\text{keras.ops.isnan} \\\\ \\hline\n",
    "\\text{tf.math.log} & \\text{keras.ops.log10} \\\\ \\hline\n",
    "\\text{tf.math.log} & \\text{keras.ops.log2} \\\\ \\hline\n",
    "\\text{tf.reduce_logsumexp} & \\text{keras.ops.logaddexp} \\\\ \\hline\n",
    "\\text{tf.reduce_max} & \\text{keras.ops.max} \\\\ \\hline\n",
    "\\text{tf.reduce_mean} & \\text{keras.ops.mean} \\\\ \\hline\n",
    "\\text{tf.reduce_min} & \\text{keras.ops.min} \\\\ \\hline\n",
    "\\text{tf.transpose} & \\text{keras.ops.moveaxis} \\\\ \\hline\n",
    "\\text{tf.rank} & \\text{keras.ops.ndim} \\\\ \\hline\n",
    "\\text{tf.linalg.matmul} & \\text{keras.ops.outer} \\\\ \\hline\n",
    "\\text{tf.math.pow} & \\text{keras.ops.power} \\\\ \\hline\n",
    "\\text{tf.reduce_prod} & \\text{keras.ops.prod} \\\\ \\hline\n",
    "\\text{tf.reshape}, \\text{tf.keras.layers.Flatten} & \\text{keras.ops.ravel} \\\\ \\hline\n",
    "\\text{tf.math.reduce_std} & \\text{keras.ops.std} \\\\ \\hline\n",
    "\\text{tf.reduce_sum} & \\text{keras.ops.sum} \\\\ \\hline\n",
    "\\text{tf.transpose} & \\text{keras.ops.swapaxes} \\\\ \\hline\n",
    "\\text{tf.gather} & \\text{keras.ops.take} \\\\ \\hline\n",
    "\\text{tf.gather_nd} & \\text{keras.ops.take_along_axis} \\\\ \\hline\n",
    "\\text{tf.linalg.matmul} & \\text{keras.ops.tensordot} \\\\ \\hline\n",
    "\\text{tf.math.divide} & \\text{keras.ops.true_divide} \\\\ \\hline\n",
    "\\text{tf.math.reduce_variance} & \\text{keras.ops.var} \\\\ \\hline\n",
    "\\text{tf.linalg.tensordot} & \\text{keras.ops.vdot} \\\\ \\hline\n",
    "\\text{tf.where} & \\text{keras.ops.where, keras.ops.nonzero} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "#### NN ops\n",
    "\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\textbf{TensorFlow} & \\textbf{Keras 3.0} \\\\\n",
    "\\hline\n",
    "\\text{tf.nn.sigmoid_cross_entropy_with_logits} &\n",
    "\\text{keras.ops.binary_crossentropy(target, output, from_logits=False)} \\\\ \\hline\n",
    "\\text{tf.nn.sparse_softmax_cross_entropy_with_logits} &\n",
    "\\text{keras.ops.categorical_crossentropy(target, output, from_logits=False, axis=-1)} \\\\\n",
    "\\hline\n",
    "\\text{tf.nn.conv1d} \\\\ \\text{tf.nn.conv2d} \\\\\n",
    "\\text{tf.nn.conv3d} \\\\ \\text{tf.nn.convolution} \\\\\n",
    "& \\text{keras.ops.conv(inputs, kernel, strides=1, padding=\"valid\",} \\\\\n",
    "& \\text{data_format=None, dilation_rate=1)} \\\\ \\hline\n",
    "\\text{tf.nn.conv_transpose} \\\\ \\text{tf.nn.conv1d_transpose} \\\\\n",
    "\\text{tf.nn.conv2d_transpose} \\\\ \\text{tf.nn.conv3d_transpose} \\\\\n",
    "& \\text{keras.ops.conv_transpose(inputs, kernel, strides, padding=\"valid\",} \\\\ \\hline\n",
    "& \\text{output_padding=None, data_format=None, dilation_rate=1)} \\\\\n",
    "\\text{tf.nn.depthwise_conv2d} & \\text{keras.ops.depthwise_conv(inputs, kernel,\n",
    "strides=1,} \\\\\n",
    "& \\text{padding=\"valid\", data_format=None, dilation_rate=1)} \\\\ \\hline\n",
    "\\text{tf.nn.separable_conv2d} & \\text{keras.ops.separable_conv(inputs, depthwise_kernel,}\n",
    "\\\\\n",
    "& \\text{pointwise_kernel, strides=1, padding=\"valid\", data_format=None,} \\\\\n",
    "& \\text{dilation_rate=1)} \\\\ \\hline\n",
    "\\text{tf.nn.sparse_softmax_cross_entropy_with_logits} &\n",
    "\\text{keras.ops.sparse_categorical_crossentropy(target, output,} \\\\\n",
    "& \\text{from_logits=False, axis=-1)} \\\\ \\hline\n",
    "\\text{tf.nn.batch_normalization} & \\text{keras.layers.BatchNormalization} \\\\ \\hline\n",
    "\\text{tf.nn.dropout} & \\text{keras.layers.Dropout} \\\\ \\hline\n",
    "\\text{tf.nn.embedding_lookup} & \\text{tf.nn.embedding_lookup_sparse} \\\\ \\hline\n",
    "\\text{tf.nn.l2_normalize} & \\text{keras.utils.normalize} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "#### Core ops\n",
    "\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\textbf{TensorFlow} & \\textbf{Keras 3.0} \\\\\n",
    "\\hline\n",
    "\\text{x.numpy} & \\text{keras.ops.convert_to_numpy} \\\\ \\hline\n",
    "\\text{NA} & \\text{keras.ops.extract_sequences(x, sequence_length, sequence_stride)} \\\\\n",
    "\\hline\n",
    "\\text{tf.scatter_nd_update} & \\text{keras.ops.scatter_update} \\\\ \\hline\n",
    "\\text{tf.tensor_scatter_nd_update} & \\text{keras.ops.slice_update} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "#### Image ops\n",
    "\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\textbf{TensorFlow} & \\textbf{Keras 3.0} \\\\\n",
    "\\hline\n",
    "\\text{tf.keras.preprocessing.image.apply_affine_transform} &\n",
    "\\text{keras.ops.image.affine_transform} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\n",
    "#### FFT ops\n",
    "\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\textbf{TensorFlow} & \\textbf{Keras 3.0} \\\\\n",
    "\\hline\n",
    "\\text{tf.signal.fft2d} & \\text{keras.ops.fft2} \\\\ \\hline\n",
    "\\text{tf.signal.inverse_stft} & \\text{keras.ops.istft} \\\\ \\hline\n",
    "\\hline\n",
    "\\end{array}\n",
    "\n",
    "#### Random ops\n",
    "\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\textbf{TensorFlow} & \\textbf{Keras 3.0} \\\\\n",
    "\\hline\n",
    "\\text{tf.random.normal} & \\text{keras.random.normal} \\\\ \\hline\n",
    "\\text{tf.random.categorical} & \\text{keras.random.categorical} \\\\ \\hline\n",
    "\\text{tf.random.uniform} & \\text{keras.random.uniform} \\\\ \\hline\n",
    "\\text{tf.random.uniform} & \\text{keras.random.randint} \\\\ \\hline\n",
    "\\text{tf.random.truncated_normal} & \\text{keras.random.truncated_normal} \\\\ \\hline\n",
    "\\text{tf.nn.dropout} & \\text{keras.layers.Dropout} \\\\ \\hline\n",
    "\\text{tf.random.shuffle} & \\text{keras.utils.shuffle} \\\\ \\hline\n",
    "\\text{Rest of tf.random.* ops} & \\text{Not yet supported} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\n",
    "#### MISC ops\n",
    "\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\textbf{TensorFlow} & \\textbf{Keras 3.0} \\\\\n",
    "\\hline\n",
    "\\text{tf.lookup.*} & \\text{Not yet supported} \\\\ \\hline\n",
    "\\text{tf.quantization.*} & \\text{Not yet supported} \\\\ \\hline\n",
    "\\text{tf.ragged.*} & \\text{Not yet supported} \\\\ \\hline\n",
    "\\text{tf.sparse.*} & \\text{All of the ops supported above also support sparse inputs for\n",
    "TensorFlow backend} \\\\\n",
    "\\hline\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Additional developer guides\n",
    "\n",
    "This wraps up the migration guide overview. We hope that this guide has been helpful in\n",
    "successfully transitioning your code from TensorFlow to Keras 3.0. Explore a variety of\n",
    "developer guides to help you begin, craft custom training loops, and establish\n",
    "distributed training setups. Take a look!\n",
    "\n",
    "* [Getting started with Keras\n",
    "Core](https://keras.io/keras_core/guides/getting_started_with_keras_core/)\n",
    "* [The Functional API](https://keras.io/keras_core/guides/functional_api/)\n",
    "* [The Sequential model](https://keras.io/keras_core/guides/sequential_model/)\n",
    "* [Making new layers & models via\n",
    "subclassing](https://keras.io/keras_core/guides/making_new_layers_and_models_via_subclassing/)\n",
    "subclassing](https://keras.io/keras_core/guides/making_new_layers_and_models_via_subclassing/)\n",
    "* [Training & evaluation with the built-in\n",
    "methods](https://keras.io/keras_core/guides/training_with_built_in_methods/)\n",
    "* [Writing your own\n",
    "callbacks](https://keras.io/keras_core/guides/writing_your_own_callbacks/)\n",
    "* [Transfer learning](https://keras.io/keras_core/guides/transfer_learning/)\n",
    "* [Understanding masking &\n",
    "padding](https://keras.io/keras_core/guides/understanding_masking_and_padding/)\n",
    "* [Customizing what happens in fit() with\n",
    "TensorFlow](https://keras.io/keras_core/guides/custom_train_step_in_tensorflow/)\n",
    "* [Customizing what happens in fit() with\n",
    "JAX](https://keras.io/keras_core/guides/custom_train_step_in_jax/)\n",
    "* [Customizing what happens in fit() with\n",
    "PyTorch](https://keras.io/keras_core/guides/custom_train_step_in_torch/)\n",
    "* [Writing a custom training loop with\n",
    "TensorFlow](https://keras.io/keras_core/guides/writing_a_custom_training_loop_in_tensorflow/)\n",
    "TensorFlow](https://keras.io/keras_core/guides/writing_a_custom_training_loop_in_tensorflow/)\n",
    "* [Writing a custom training loop with\n",
    "JAX](https://keras.io/keras_core/guides/writing_a_custom_training_loop_in_jax/)\n",
    "* [Writing a custom training loop with\n",
    "PyTorch](https://keras.io/keras_core/guides/writing_a_custom_training_loop_in_torch/)\n",
    "* [Distributed training with\n",
    "TensorFlow](https://keras.io/keras_core/guides/distributed_training_with_tensorflow/)\n",
    "* [Distributed training with\n",
    "JAX](https://keras.io/keras_core/guides/distributed_training_with_jax/)\n",
    "* [Distributed training with\n",
    "PyTorch](https://keras.io/keras_core/guides/distributed_training_with_torch/)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "None",
  "colab": {
   "collapsed_sections": [],
   "name": "migration_guide_tf_keras_3_0",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}