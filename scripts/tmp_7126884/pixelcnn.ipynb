{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# PixelCNN\n",
    "\n",
    "**Author:** ADMoreau<br>\n",
    "**Date created:** 2020/05/17<br>\n",
    "**Last modified:** 2020/05/20<br>\n",
    "**Description:** PixelCNN implemented in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras, nn\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#Getting the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "n_residual_blocks = 5\n",
    "# the data, split between train and test sets\n",
    "(x, _), (y, _) = keras.datasets.mnist.load_data()\n",
    "# Concatenate all of the images together\n",
    "data = np.concatenate((x, y), axis=0)\n",
    "# round all pixel values less than 33% of the max 256 value to 0\n",
    "# anything above this value gets rounded up to 1 so that all values are either\n",
    "# 0 or 1\n",
    "data = np.where(data < (0.33 * 256), 0, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#Create two classes for the requisite Layers for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# the first layer to create will be the PixelCNN layer, this layer is simply\n",
    "# the 2D convolutional layer with the masking included\n",
    "class PixelConvLayer(keras.layers.Conv2D):\n",
    "    def __init__(self, mask_type, *args, **kwargs):\n",
    "        super(PixelConvLayer, self).__init__(*args, **kwargs)\n",
    "        self.mask_type = mask_type\n",
    "        self.mask = None\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self._recreate_conv_op(inputs):\n",
    "            self._convolution_op = nn_ops.Convolution(\n",
    "                inputs.get_shape(),\n",
    "                filter_shape=self.kernel.shape,\n",
    "                dilation_rate=self.dilation_rate,\n",
    "                strides=self.strides,\n",
    "                padding=self._padding_op,\n",
    "                data_format=self._conv_op_data_format,\n",
    "            )\n",
    "\n",
    "        # Apply causal padding to inputs for Conv1D.\n",
    "        if self.padding == \"causal\" and self.__class__.__name__ == \"Conv1D\":\n",
    "            inputs = array_ops.pad(inputs, self._compute_causal_padding())\n",
    "\n",
    "        # The divergence from the original 2D conv. layer is here, where we\n",
    "        # create the mask depending on which layer we are using\n",
    "        if self.mask is None:\n",
    "            kernel_shape = self.kernel.get_shape()\n",
    "            self.mask = np.zeros(shape=kernel_shape)\n",
    "            self.mask[: kernel_shape[0] // 2, ...] = 1.0\n",
    "            self.mask[kernel_shape[0] // 2, : kernel_shape[1] // 2, ...] = 1.0\n",
    "            if self.mask_type == \"B\":\n",
    "                self.mask[kernel_shape[0] // 2, kernel_shape[1] // 2, ...] = 1\n",
    "\n",
    "        # and here we apply the mask to convoltional kernal\n",
    "        outputs = self._convolution_op(inputs, self.kernel * self.mask)\n",
    "\n",
    "        if self.use_bias:\n",
    "            if self.data_format == \"channels_first\":\n",
    "                if self.rank == 1:\n",
    "                    # nn.bias_add does not accept a 1D input tensor.\n",
    "                    bias = array_ops.reshape(self.bias, (1, self.filters, 1))\n",
    "                    outputs += bias\n",
    "                else:\n",
    "                    outputs = nn.bias_add(outputs, self.bias, data_format=\"NCHW\")\n",
    "            else:\n",
    "                outputs = nn.bias_add(outputs, self.bias, data_format=\"NHWC\")\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# Next we build our residual block layer,\n",
    "# this is just a normal res. block but with the PixelConvLayer built in\n",
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(ResidualBlock, self).__init__(**kwargs)\n",
    "        self.a = keras.layers.ReLU()\n",
    "        self.b = keras.layers.Conv2D(filters=filters, kernel_size=1, activation=\"relu\")\n",
    "        self.c = PixelConvLayer(\n",
    "            mask_type=\"B\",\n",
    "            filters=filters // 2,\n",
    "            kernel_size=3,\n",
    "            activation=\"relu\",\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        self.d = keras.layers.Conv2D(filters=filters, kernel_size=1, activation=\"relu\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.a(inputs)\n",
    "        x = self.b(x)\n",
    "        x = self.c(x)\n",
    "        x = self.d(x)\n",
    "        return keras.layers.add([inputs, x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Build the model based on the original paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "PixelCNN_input = keras.Input(shape=input_shape)\n",
    "x = PixelConvLayer(\n",
    "    mask_type=\"A\", filters=128, kernel_size=7, padding=\"same\", activation=\"relu\"\n",
    ")(PixelCNN_input)\n",
    "\n",
    "for _ in range(n_residual_blocks):\n",
    "    x = ResidualBlock(filters=128)(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    x = PixelConvLayer(\n",
    "        mask_type=\"B\",\n",
    "        filters=128,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        activation=\"relu\",\n",
    "        padding=\"valid\",\n",
    "    )(x)\n",
    "\n",
    "x = keras.layers.Conv2D(\n",
    "    filters=1, kernel_size=1, strides=1, activation=\"sigmoid\", padding=\"valid\"\n",
    ")(x)\n",
    "\n",
    "PixelCNN = keras.Model(PixelCNN_input, x)\n",
    "adam = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "PixelCNN.compile(optimizer=adam, loss=\"binary_crossentropy\")\n",
    "\n",
    "PixelCNN.summary()\n",
    "PixelCNN.fit(\n",
    "    x=data.astype(\"float32\"),\n",
    "    y=data.astype(\"float32\"),\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    validation_split=0.1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Demo\n",
    "\n",
    "The PixelCNN cannot create the full image at once and must instead create each pixel in\n",
    "order, append the next created pixel to current image, and feed the image back into the\n",
    "model to repeat the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# Create an empty array of pixels.\n",
    "batch = 4\n",
    "pixels = np.zeros(shape=(batch,) + (PixelCNN.input_shape)[1:])\n",
    "batch, rows, cols, channels = pixels.shape\n",
    "\n",
    "# Iterate the pixels because generation has to be done sequentially pixel by pixel.\n",
    "for row in tqdm(range(rows)):\n",
    "    for col in range(cols):\n",
    "        for channel in range(channels):\n",
    "            # Feed the whole array and retrieving the pixel value probabilities for the next\n",
    "            # pixel.\n",
    "            p = PixelCNN.predict_on_batch(pixels)[:, row, col, channel]\n",
    "            # Use the probabilities to pick pixel values and append the values to the image\n",
    "            # frame.\n",
    "            pixels[:, row, col, channel] = bernoulli.rvs(size=batch, p=p)\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # stack the single channeled black and white image to rgb values.\n",
    "    x = np.stack((x, x, x), 2)\n",
    "    # Undo preprocessing\n",
    "    x *= 255.0\n",
    "    # Convert to uint8 and clip to the valid range [0, 255]\n",
    "    x = np.clip(x, 0, 255).astype(\"uint8\")\n",
    "    return x\n",
    "\n",
    "\n",
    "# Iterate the generated images and plot them with matplotlib.\n",
    "for i, pic in enumerate(pixels):\n",
    "    keras.preprocessing.image.save_img(\n",
    "        \"generated_image_{}.png\".format(i), deprocess_image(np.squeeze(pic, -1))\n",
    "    )\n",
    "\n",
    "display(Image(\"generated_image_0.png\"))\n",
    "display(Image(\"generated_image_1.png\"))\n",
    "display(Image(\"generated_image_2.png\"))\n",
    "display(Image(\"generated_image_3.png\"))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pixelcnn",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}